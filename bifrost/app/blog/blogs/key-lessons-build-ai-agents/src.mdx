Making AI agents think better is more crucial than just feeding them more data. Patrick highlights that the real competitive edge isn't just in the agents themselves but in the infrastructure supporting them. 

![Key Lessons from Building AI Agents](/static/blog/ai-agent-key-lessons-cover.webp)

## The TL;DR

In "Building AI Agents: Lessons Learned over the past Year," **Patrick Dougherty** shares his hands-on experience from a year of developing AI agents. He emphasizes that making AI agents think better is more crucial than just feeding them more data. **<span style={{color: '#0ea5e9'}}>Patrick highlights that the real competitive edge isn't just in the agents themselves but in the infrastructure supporting them</span>**.

## Key Insights for Building Effective AI Agents

1. Reasoning over memorization: enhancing ai agent thought processes
2. The critical role of the agent-computer interface (ACI)
3. Navigating the limitations of current AI models
4. Why fine-tuning may hinder your AI agent
5. Steer clear of over-abstraction with third-party libraries
6. Infrastructure is your competitive advantage, not the agent
7. Preparing for future advances in AI models

## About the Author

**Patrick Dougherty** is an AI practitioner who has spent the past year in building and refining AI agents. Collaborating with engineers and UX designers, he’s focused on creating platforms that allow businesses to use standard data analysis agents and develop custom ones tailored to specific tasks. With hands-on experience integrating AI agents into Fortune 500 companies, Patrick brings practical insights into deploying AI in real-world scenarios.

## What We've Learned
**<span style={{color: '#0ea5e9'}}>Reasoning is more important than knowledge</span>**
- *Thinking Over Recalling*: Agents should be designed to reason through problems, not just recall information.
- *Handle Failures Gracefully*: Design agents to learn from errors (e.g., SQL query failures) and iteratively improve outcomes.

**<span style={{color: '#0ea5e9'}}>The best way to improve performance is by iterating on the Agent-Computer Interface (ACI)</span>**
- *Continuous Refinement*: Regularly adjust the syntax and structure of tool calls to enhance agent understanding.
- *Model-Specific Adjustments*: Tailor the ACI to suit the strengths and weaknesses of different AI models.

**<span style={{color: '#0ea5e9'}}>Agents are limited by their models</span>**
- *Model Choice Matters*: The underlying AI model significantly affects agent performance and decision-making capabilities.
- *Comparative Performance*: Higher-end models like GPT-4 outperform others in planning and executing complex tasks.

**<span style={{color: '#0ea5e9'}}>Fine-tuning models to improve agent performance is a waste of time</span>**
- *Avoid Over-Reliance on Examples*: Fine-tuned models may struggle with reasoning through new, unseen problems.
- *Selective Use of Fine-Tuning*: It may be beneficial for specific tasks but not for overall agent reasoning.

**<span style={{color: '#0ea5e9'}}>If you're building a product, avoid using abstractions like LangChain and LlamaIndex</span>**
- *Maintain Direct Control*: Owning each model interaction aids in debugging and scalability.
- *Understand Inputs and Outputs*: Direct management leads to more robust and adaptable agents.

**<span style={{color: '#0ea5e9'}}>Your agent is not your moat</span>**
- *Focus on Infrastructure*: Competitive advantage lies in security, data connectors, user interface, long-term memory, and evaluation frameworks.
- *Critical Components*:
    - **Security**: Protect user data and control access.
    - **Data Connectors**: Ensure seamless integration with various databases and APIs.
    - **User Interface**: Create transparent and interactive experiences for users.
    - **Long-Term Memory**: Implement mechanisms for the agent to retain and recall past information.
    - **Evaluation**: Develop frameworks to assess and improve agent performance.

**<span style={{color: '#0ea5e9'}}>Don’t bet against models continuing to improve</span>**
- *Design for Adaptability*: Build agents that can easily integrate advancements in AI models.
- *Avoid Over-Customization*: Overfitting to current models may hinder future compatibility and performance.

**<span style={{color: '#0ea5e9'}}>Additional lessons learned</span>**
- *Open-Source Models May Lag Behind*: Currently, they might not match proprietary models in reasoning abilities.
- *Premature Optimization Can Backfire*: Focus on functionality before cost-cutting.
- *Enhance User Experience*: Implement features like token streaming to improve perceived performance.
- *Embrace Iterative Development*: Continuously learn and adapt to improve AI agents.

## What are your thoughts?

Anything else you’d like to add? Please <a href="https://github.com/Helicone/helicone/pulls" target="_blank" rel="noopener noreferrer">raise an issue</a> and we’d love to share your tips!